import{_ as ne}from"./DetailHeader.vue_vue_type_script_setup_true_lang-db011269.js";import{_ as j}from"./ToolDetail.vue_vue_type_script_setup_true_lang-2e61e02d.js";import{d as re,l as H,A as se,r as oe,b as _,c as w,i as I,f as n,t as ae,F as $,e as M,P as L,D as ie,h as V,j as P,_ as ce}from"./index-2d04b938.js";const ue={class:"flex flex-col mt-3 flex-1"},fe={class:"p-4 rounded-2xl bg-white"},me={class:"flex flex-col items-center"},de={class:"mb-4 text-center"},ve={class:"text-lg font-semibold mb-2"},xe=["viewBox"],pe=["x1","x2","y2"],he=["y1","x2","y2"],be=["onClick"],i=15,d=40,p=20,ye=re({__name:"AiGomoku",setup(ge){const U=H({title:"AI五子棋"}),X={width:`${i*d+p*2}px`,height:`${i*d+p*2}px`},u=H({board:Array(i).fill(null).map(()=>Array(i).fill(0)),currentPlayer:1,gameOver:!1,winner:0}),y=se(!1),b={me:2,maxDepth:6,timeLimitPerMove:600,searchRadius:2},z=(()=>{const t=()=>Math.floor(Math.random()*4294967296)>>>0,e=[];for(let r=0;r<i;r++){e[r]=[];for(let l=0;l<i;l++)e[r][l]=[t(),t()]}return e})(),Z=t=>{let e=0;for(let r=0;r<i;r++)for(let l=0;l<i;l++){const s=t[r][l];s===1?e=(e^z[r][l][0]>>>0)>>>0:s===2&&(e=(e^z[r][l][1]>>>0)>>>0)}return e>>>0},B=new Map,k=(t,e)=>t>=0&&t<i&&e>=0&&e<i,C=(t,e=b.searchRadius)=>{const r=Array(i).fill(null).map(()=>Array(i).fill(!1));let l=!1;for(let o=0;o<i;o++)for(let a=0;a<i;a++)if(t[o][a]!==0){l=!0;for(let c=-e;c<=e;c++)for(let m=-e;m<=e;m++){const f=o+c,x=a+m;k(f,x)&&t[f][x]===0&&(r[f][x]=!0)}}const s=[];if(!l){const o=Math.floor(i/2);return s.push({row:o,col:o}),s}for(let o=0;o<i;o++)for(let a=0;a<i;a++)t[o][a]===0&&r[o][a]&&s.push({row:o,col:a});return s},S=[[1,0],[0,1],[1,1],[1,-1]],q=(t,e)=>t>=5?1e8:t===4&&e===2?1e7:t===4&&e===1?1e6:t===3&&e===2?1e5:t===3&&e===1?1e4:t===2&&e===2?1e3:t===2&&e===1?100:t*10,D=(t,e)=>{let r=0;for(let l=0;l<i;l++)for(let s=0;s<i;s++)if(t[l][s]===e)for(const[o,a]of S){let c=1,m=0;for(let f=1;f<5;f++){const x=l+o*f,h=s+a*f;if(!k(x,h))break;if(t[x][h]===e)c++;else{t[x][h]===0&&m++;break}}for(let f=1;f<5;f++){const x=l-o*f,h=s-a*f;if(!k(x,h))break;if(t[x][h]===e)c++;else{t[x][h]===0&&m++;break}}r+=q(c,m)}return r},J=t=>{const e=(i-1)/2;let r=0;for(let l=0;l<i;l++)for(let s=0;s<i;s++)if(t[l][s]!==0){const o=Math.abs(l-e)+Math.abs(s-e);r-=o}return r},R=(t,e)=>{const r=e===1?2:1,l=D(t,e),s=D(t,r);return l-s*1.1+J(t)*20},K=(t,e,r,l)=>{for(const[s,o]of S){let a=1;for(let c=1;c<5;c++){const m=e+s*c,f=r+o*c;if(!k(m,f)||t[m][f]!==l)break;a++}for(let c=1;c<5;c++){const m=e-s*c,f=r-o*c;if(!k(m,f)||t[m][f]!==l)break;a++}if(a>=5)return!0}return!1},O=(t,e)=>{const r=C(t);for(const l of r){t[l.row][l.col]=e;const s=K(t,l.row,l.col,e);if(t[l.row][l.col]=0,s)return l}return null},W=(t,e,r,l,s,o,a,c)=>{if(performance.now()-a>c)return{value:0,move:null,aborted:!0};const m=Z(t),f=B.get(m);if(f&&f.depth>=e)return{value:f.value,move:null};const x=O(t,o*s);if(x)return{value:1e8+e,move:x};if(e===0)return{value:s*R(t,o),move:null};let h=-1/0,F=null;const le=C(t).map(v=>{t[v.row][v.col]=o*s;const g=R(t,o);return t[v.row][v.col]=0,{mv:v,v:g}}).sort((v,g)=>g.v-v.v).map(v=>v.mv);for(const v of le){t[v.row][v.col]=o*s;const g=W(t,e-1,-l,-r,-s,o,a,c);if(t[v.row][v.col]=0,g.aborted)return{value:0,move:null,aborted:!0};const N=-g.value;if(N>h&&(h=N,F=v),r=Math.max(r,N),r>=l)break}return B.set(m,{depth:e,value:h}),{value:h,move:F}},Q=async(t,e,r,l)=>{const s=performance.now();B.clear();let o=null,a=-1/0;for(let c=1;c<=r&&!(l-(performance.now()-s)<=10);c++){const f=W(t,c,-1/0,1/0,1,e,s,l);if(f.aborted||(f.move&&(o=f.move,a=f.value),a>5e7))break;await new Promise(x=>setTimeout(x,0))}return o},A=(t,e)=>{u.board[t][e]=b.me,G(t,e,b.me)?(u.gameOver=!0,u.winner=b.me):T()?(u.gameOver=!0,u.winner=0):u.currentPlayer=1,y.value=!1},Y=(t,e)=>{if(!(u.gameOver||u.board[t][e]!==0||y.value)){if(u.board[t][e]=u.currentPlayer,G(t,e,u.currentPlayer)){u.gameOver=!0,u.winner=u.currentPlayer;return}if(T()){u.gameOver=!0,u.winner=0;return}u.currentPlayer=b.me,y.value=!1,(async()=>{const r=u.board.map(a=>a.slice()),l=O(r,b.me);if(l){A(l.row,l.col);return}const s=O(r,1);if(s){A(s.row,s.col);return}const o=await Q(r,b.me,b.maxDepth,b.timeLimitPerMove);if(o)A(o.row,o.col);else{const a=C(r);if(a.length>0){const c=a[Math.floor(Math.random()*a.length)];A(c.row,c.col)}else y.value=!1,u.currentPlayer=1}})()}},G=(t,e,r)=>{for(const[l,s]of S){let o=1;for(let a=1;a<5;a++){const c=t+l*a,m=e+s*a;if(c<0||c>=i||m<0||m>=i||u.board[c][m]!==r)break;o++}for(let a=1;a<5;a++){const c=t-l*a,m=e-s*a;if(c<0||c>=i||m<0||m>=i||u.board[c][m]!==r)break;o++}if(o>=5)return!0}return!1},T=()=>u.board.every(t=>t.every(e=>e!==0)),E=()=>{u.board=Array(i).fill(null).map(()=>Array(i).fill(0)),u.currentPlayer=1,u.gameOver=!1,u.winner=0,y.value=!1},ee=(t,e)=>{const r=u.board[t][e];return r===0?"empty":r===1?"black":r===2?"white":""},te=()=>{if(u.gameOver){if(u.winner===0)return"游戏结束，平局！";if(u.winner===1)return"恭喜！你赢了！";if(u.winner===2)return"AI赢了！再试一次吧！"}return y.value?"AI正在思考...":u.currentPlayer===1?"轮到你了（黑子）":"轮到AI（白子）"};return(t,e)=>{const r=oe("el-text");return _(),w("div",ue,[I(ne,{title:U.title},null,8,["title"]),n("div",fe,[n("div",me,[n("div",de,[n("div",ve,ae(te()),1),n("button",{onClick:E,class:"px-4 py-2 bg-blue-500 text-white rounded hover:bg-blue-600 transition-colors"}," 重新开始 ")]),n("div",{class:"relative",style:X},[e[0]||(e[0]=n("div",{class:"absolute inset-0 bg-amber-100 rounded-lg"},null,-1)),(_(),w("svg",{class:"absolute inset-0 w-full h-full",viewBox:`0 0 ${i*d+p*2} ${i*d+p*2}`},[(_(),w($,null,M(i,l=>n("line",{key:`v${l}`,x1:p+(l-1)*d,y1:p,x2:p+(l-1)*d,y2:p+(i-1)*d,stroke:"#8B4513","stroke-width":"1"},null,8,pe)),64)),(_(),w($,null,M(i,l=>n("line",{key:`h${l}`,x1:p,y1:p+(l-1)*d,x2:p+(i-1)*d,y2:p+(l-1)*d,stroke:"#8B4513","stroke-width":"1"},null,8,he)),64))],8,xe)),(_(),w($,null,M(i,l=>n("div",{key:`row-${l-1}`,class:"absolute",style:L({top:`${p+(l-1)*d-d/2}px`,left:`${p-d/2}px`,width:`${i*d}px`,height:`${d}px`})},[(_(),w($,null,M(i,s=>n("div",{key:`${l-1}-${s-1}`,class:ie(["absolute cursor-pointer transition-all duration-200 hover:scale-110",ee(l-1,s-1)]),style:L({left:`${(s-1)*d}px`,width:`${d}px`,height:`${d}px`}),onClick:o=>Y(l-1,s-1)},null,14,be)),64))],4)),64))]),e[1]||(e[1]=n("div",{class:"mt-6 text-center text-gray-600"},[n("p",null,"点击棋盘落子，与AI对战五子棋！"),n("p",null,"黑子先手，先连成五子者获胜。")],-1))])]),I(j,{title:"描述"},{default:V(()=>[I(r,null,{default:V(()=>e[2]||(e[2]=[P(" AI五子棋是一款智能对战游戏，玩家执黑子，AI执白子。游戏采用经典的15×15棋盘，支持鼠标点击落子，具有智能AI对手，能够进行策略性对战。游戏包含胜负判定、平局检测等功能，适合休闲娱乐和策略思维训练。 ",-1)])),_:1,__:[2]})]),_:1}),I(j,{title:"AI算法原理"},{default:V(()=>e[3]||(e[3]=[n("div",{class:"space-y-4"},[n("div",null,[n("h4",{class:"font-semibold text-lg mb-2"},"算法架构"),n("p",{class:"text-gray-700 mb-2"},"我们把AI能力分成两类职责："),n("ul",{class:"list-disc list-inside space-y-1 text-gray-600"},[n("li",null,[n("strong",null,"搜索（Search）"),P("：在若干可能走法中寻找最优走子 —— 用Negamax + Alpha-Beta、迭代加深、时间限制等实现")]),n("li",null,[n("strong",null,"评估（Evaluation）"),P("：当搜索走到深度底或叶节点时，为当前局面打分 —— 用棋型识别（活四/冲四/活三/眠三……）和位置权重")])])]),n("div",null,[n("h4",{class:"font-semibold text-lg mb-2"},"核心算法"),n("div",{class:"space-y-3"},[n("div",null,[n("h5",{class:"font-medium text-blue-600"},"1. Negamax算法"),n("p",{class:"text-gray-600 text-sm"},'Negamax是Minimax的变体，利用对称性把"最大化对我分数 = 最小化对方分数"的关系合并成统一函数，代码更简洁，易与Alpha-Beta、置换表配合。')]),n("div",null,[n("h5",{class:"font-medium text-blue-600"},"2. Alpha-Beta剪枝"),n("p",{class:"text-gray-600 text-sm"},"在Negamax上加上下界（alpha）和上界（beta），当某个分支不能影响根节点决策时就剪掉，在合理的走法排序下能把搜索树大小从O(b^d)大幅降为O(b^{d/2})。")]),n("div",null,[n("h5",{class:"font-medium text-blue-600"},"3. 迭代加深"),n("p",{class:"text-gray-600 text-sm"},"从浅到深逐层运行搜索（深度1,2,3...），每层都保存当前最佳走法。能在任何时间点都有一个可用解，配合时间限制很重要。")]),n("div",null,[n("h5",{class:"font-medium text-blue-600"},"4. 候选走法生成"),n("p",{class:"text-gray-600 text-sm"},"只考虑靠近已有棋子的空位（搜索半径=2），或在空盘只考虑中心。五子棋的合理走子大多发生在已有棋子附近，过滤孤立点能大幅降低分支因子。")]),n("div",null,[n("h5",{class:"font-medium text-blue-600"},"5. 立即获胜/阻挡检测"),n("p",{class:"text-gray-600 text-sm"},'在正式深搜前先检测"落子立刻获胜"或"必须阻挡对手的立刻获胜"，若存在直接走法就优先执行，避免浪费搜索预算。')]),n("div",null,[n("h5",{class:"font-medium text-blue-600"},"6. 评估函数"),n("p",{class:"text-gray-600 text-sm"},"识别常见棋型并赋权：五连(1e8)、活四(1e7)、冲四(1e6)、活三(1e5)、眠三(1e4)、活二(1e3)。对敌方棋型赋负分，防守权重略微放大，促使AI在对手有威胁时更偏向阻挡。")]),n("div",null,[n("h5",{class:"font-medium text-blue-600"},"7. 置换表 + Zobrist哈希"),n("p",{class:"text-gray-600 text-sm"},"为棋盘中每个位置和每种棋子分配随机数，棋局哈希是对这些随机数做XOR的结果。用哈希把已评估局面和深度/分值缓存起来，节省大量重复计算。")]),n("div",null,[n("h5",{class:"font-medium text-blue-600"},"8. 走法排序"),n("p",{class:"text-gray-600 text-sm"},'Alpha-Beta的效率极度依赖先搜索到"好走法"。把"立即获胜走法"放在最前面，先按静态评估对候选走法排序，越早找到高分走法，越多后续分支被剪掉。')])])]),n("div",null,[n("h4",{class:"font-semibold text-lg mb-2"},"工作流程"),n("ol",{class:"list-decimal list-inside space-y-1 text-gray-600"},[n("li",null,"用户落子 → 检查胜负/平局"),n("li",null,"切换AI：先查找我方必胜 → 若无，再查找必堵 → 若都无，进入深搜"),n("li",null,"使用迭代加深（depth = 1..maxDepth），每层调用negamax（带alpha-beta、置换表、时间检测）"),n("li",null,"搜索中若超时则中断，返回当前bestMove"),n("li",null,"应用走子，更新状态，UI更新")])]),n("div",{class:"bg-blue-50 p-3 rounded-lg"},[n("p",{class:"text-blue-800 text-sm"},[n("strong",null,"技术特点："),P("搜索深度6层，时间限制600ms，搜索半径2格，支持异步计算和超时中断，确保AI既能快速响应又具备足够的策略深度。 ")])])],-1)])),_:1,__:[3]})])}}});const Ie=ce(ye,[["__scopeId","data-v-99575c73"]]);export{Ie as default};
